kmeans.dust <- kmeans(dust_n, 2)
dust_origin <- read.csv("D:/Study/Data Science/dust_day2.csv", stringsAsFactors = TRUE)
# shuffle
set.seed(1)
dust_shuffle <- dust_origin[sample(nrow(dust_origin)),]
dust_df <- dust_shuffle[-c(1:3)] # 필요없는 변수 제거
# 정규화
normalize <- function(x) {
return ((x-min(x))/(max(x)-min(x)))
}
ncol(dust_df)
dust_n <- as.data.frame(lapply(dust_df[2:7], normalize))
# train(90%) / test(10%)
train_num <- round(0.9*nrow(dust_n),0)
dust_train <- dust_n[1:train_num,]
dust_test <- dust_n[(train_num+1):nrow(dust_n),]
dust_train_label <- dust_df[1:train_num,1]
dust_test_label <- dust_df[(train_num+1):nrow(dust_n),1]
# kmeans 사용
library(stats)
# test 데이터를 2개로 군집화
result <- kmeans(dust_test,2)
# 라벨링된 것이 어떤 의미인지는 내가 알아내야 한다.
result$cluster
dust_test_label
# 시각화
library(factoextra)
fviz_cluster(result,data=dust_test,stand=T)
# test_label도 숫자로 바꿔줌
dust_test_label
label_check <- ifelse(dust_test_label==1,2,1)
label_check
# 군집화의 정확도 확인
real <- length(label_check)
predict <- sum(label_check==result$cluster)
predict/real*100
kmeans.dust <- kmeans(dust_n, 2)
round(sum(kmeans.dust$withinss), 2)
kmeans.dust$cluster
kmeans.dust <- kmeans(dust_n, 2, nstart=10)
round(sum(kmeans.dust$withinss), 2)
round(sum(kmeans.dust$betweenss), 2)
visual <- NULL
for(i in 2:6)
{
set.seed(0723)
eval(parse(text=paste("result",i,"<- kmeans(dust_n,",i,");",sep="")))
eval(parse(text=paste("visual[",i,"] <- result",i,"$tot.withinss",sep="")))
}
plot(visual[-1], type="l", ylab="", xlab="", main="cluster의 개수에 따른 내부분산")
abline(v=3,col="red")
for(i in 2:10)
{
set.seed(0723)
eval(parse(text=paste("result",i,"<- kmeans(dust_n,",i,");",sep="")))
eval(parse(text=paste("visual[",i,"] <- result",i,"$tot.withinss",sep="")))
}
plot(visual[-1], type="l", ylab="", xlab="", main="cluster의 개수에 따른 내부분산")
abline(v=3,col="red")
# train(90%) / test(10%)
train_num <- round(0.9*nrow(dust_n),0)
dust_train <- dust_n[1:train_num,]
dust_test <- dust_n[(train_num+1):nrow(dust_n),]
dust_train_label <- dust_df[1:train_num,1]
dust_test_label <- dust_df[(train_num+1):nrow(dust_n),1]
# kmeans 사용
library(stats)
# test 데이터를 2개로 군집화
result <- kmeans(dust_test,3)
# 라벨링된 것이 어떤 의미인지는 내가 알아내야 한다.
result$cluster
dust_test_label
# 시각화
library(factoextra)
fviz_cluster(result,data=dust_test,stand=T)
# test_label도 숫자로 바꿔줌
dust_test_label
label_check <- ifelse(dust_test_label==1,2,1)
label_check
# 군집화의 정확도 확인
real <- length(label_check)
predict <- sum(label_check==result$cluster)
predict/real*100
kmeans.dust <- kmeans(dust_n, 2, nstart=10)
round(sum(kmeans.dust$betweenss), 2)
kmeans.dust$cluster
visual <- NULL
for(i in 2:10)
{
set.seed(0723)
eval(parse(text=paste("result",i,"<- kmeans(dust_n,",i,");",sep="")))
eval(parse(text=paste("visual[",i,"] <- result",i,"$tot.withinss",sep="")))
}
plot(visual[-1], type="l", ylab="", xlab="", main="cluster의 개수에 따른 내부분산")
abline(v=3,col="red")
